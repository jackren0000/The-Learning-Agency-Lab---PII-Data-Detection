{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf55167",
   "metadata": {
    "papermill": {
     "duration": 0.003584,
     "end_time": "2024-02-02T06:34:06.403547",
     "exception": false,
     "start_time": "2024-02-02T06:34:06.399963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define the objectives:\n",
    "know insight of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b30260",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-02T06:34:06.412114Z",
     "iopub.status.busy": "2024-02-02T06:34:06.411454Z",
     "iopub.status.idle": "2024-02-02T06:34:29.257255Z",
     "shell.execute_reply": "2024-02-02T06:34:29.256075Z"
    },
    "papermill": {
     "duration": 22.85308,
     "end_time": "2024-02-02T06:34:29.259945",
     "exception": false,
     "start_time": "2024-02-02T06:34:06.406865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 06:34:18.953092: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-02 06:34:18.953222: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-02 06:34:19.103649: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "#### import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "# import argparse library to handle command-line arguments\n",
    "import argparse\n",
    "# a Hugging Face Dataset used for natural language processing (NLP)\n",
    "from datasets import Dataset\n",
    "from pathlib import Path\n",
    "# import the 'chain' function to combine multiple iterables into a single iterable\n",
    "from itertools import chain\n",
    "# tokenizer that can automatically find the model's required tokenization from the model name\n",
    "from transformers import AutoTokenizer\n",
    "# model class that can automatically find a token classification model from the model name\n",
    "from transformers import AutoModelForTokenClassification\n",
    "# class that provides an API for feature-compplete training in PyTorch\n",
    "from transformers import Trainer\n",
    "# class to store hyperparameters for training\n",
    "from transformers import TrainingArguments\n",
    "# data collator that dynamically pads the inputs received, used for token classification tasks\n",
    "from transformers import DataCollatorForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbfa243",
   "metadata": {
    "papermill": {
     "duration": 0.003041,
     "end_time": "2024-02-02T06:34:29.266469",
     "exception": false,
     "start_time": "2024-02-02T06:34:29.263428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e4d72b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T06:34:29.275102Z",
     "iopub.status.busy": "2024-02-02T06:34:29.274279Z",
     "iopub.status.idle": "2024-02-02T06:34:31.785842Z",
     "shell.execute_reply": "2024-02-02T06:34:31.784641Z"
    },
    "papermill": {
     "duration": 2.518601,
     "end_time": "2024-02-02T06:34:31.788498",
     "exception": false,
     "start_time": "2024-02-02T06:34:29.269897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the JSON file content\n",
    "\n",
    "with open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\", 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d170ece",
   "metadata": {
    "papermill": {
     "duration": 0.002943,
     "end_time": "2024-02-02T06:34:31.794824",
     "exception": false,
     "start_time": "2024-02-02T06:34:31.791881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a44973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T06:34:31.802891Z",
     "iopub.status.busy": "2024-02-02T06:34:31.802532Z",
     "iopub.status.idle": "2024-02-02T06:34:31.812910Z",
     "shell.execute_reply": "2024-02-02T06:34:31.811654Z"
    },
    "papermill": {
     "duration": 0.018598,
     "end_time": "2024-02-02T06:34:31.816552",
     "exception": false,
     "start_time": "2024-02-02T06:34:31.797954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Data Size ###\n",
      "The length of the data is: 6807\n",
      "\n",
      "### Sample Keys ###\n",
      "The keys of the data is: dict_keys(['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels'])\n",
      "\n",
      "### Sample Document Number ###\n",
      "The document of this sample is: 7\n",
      "\n",
      "### Sample Full Text ###\n",
      "The full_text of this sample is: Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n",
      "\n",
      "Challenge & selection\n",
      "\n",
      "The tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\n",
      "\n",
      "What exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf Annex1\n",
      "\n",
      "This tool has many advantages:\n",
      "\n",
      "•  It is accessible to all and does not require significant material investment and can be done  quickly\n",
      "\n",
      "•  It is scalable\n",
      "\n",
      "•  It allows categorization and linking of information\n",
      "\n",
      "•  It can be applied to any type of situation: notetaking, problem solving, analysis, creation of  new ideas\n",
      "\n",
      "•  It is suitable for all people and is easy to learn\n",
      "\n",
      "•  It is fun and encourages exchanges\n",
      "\n",
      "•  It makes visible the dimension of projects, opportunities, interconnections\n",
      "\n",
      "•  It synthesizes\n",
      "\n",
      "•  It makes the project understandable\n",
      "\n",
      "•  It allows you to explore ideas\n",
      "\n",
      "The creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.\n",
      "\n",
      "This tool enables creativity and logic to be mobilized, it is a map of the thoughts.\n",
      "\n",
      "Creativity is enhanced because participants feel comfortable with the method.\n",
      "\n",
      "Application & Insight\n",
      "\n",
      "I start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.\n",
      "\n",
      "Through a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.\n",
      "\n",
      "The use of the “why” is very interesting to understand the origin. By this way, the interviewed person  frees itself from paradigms and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.\n",
      "\n",
      "Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n",
      "\n",
      "After modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and interconnections. This second workshop also lasts  two hours and allows the mind map to evolve. Once familiarized with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have learned to work  together and want to make visible the untold ideas.\n",
      "\n",
      "I now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.\n",
      "\n",
      "Approach\n",
      "\n",
      "What I find amazing with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.\n",
      "\n",
      "Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n",
      "\n",
      "Annex 1: Mind Map Shared facilities project\n",
      "\n",
      "\n",
      "\n",
      "### Sample Tokens ###\n",
      "The tokens of this sample is: ['Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'Challenge', '&', 'selection', '\\n\\n', 'The', 'tool', 'I', 'use', 'to', 'help', 'all', 'stakeholders', 'finding', 'their', 'way', 'through', 'the', 'complexity', 'of', 'a', 'project', 'is', 'the', ' ', 'mind', 'map', '.', '\\n\\n', 'What', 'exactly', 'is', 'a', 'mind', 'map', '?', 'According', 'to', 'the', 'definition', 'of', 'Buzan', 'T.', 'and', 'Buzan', 'B.', '(', '1999', ',', 'Dessine', '-', 'moi', ' ', \"l'intelligence\", '.', 'Paris', ':', 'Les', 'Éditions', \"d'Organisation\", '.', ')', ',', 'the', 'mind', 'map', '(', 'or', 'heuristic', 'diagram', ')', 'is', 'a', 'graphic', ' ', 'representation', 'technique', 'that', 'follows', 'the', 'natural', 'functioning', 'of', 'the', 'mind', 'and', 'allows', 'the', 'brain', \"'s\", ' ', 'potential', 'to', 'be', 'released', '.', 'Cf', 'Annex1', '\\n\\n', 'This', 'tool', 'has', 'many', 'advantages', ':', '\\n\\n', '•', ' ', 'It', 'is', 'accessible', 'to', 'all', 'and', 'does', 'not', 'require', 'significant', 'material', 'investment', 'and', 'can', 'be', 'done', ' ', 'quickly', '\\n\\n', '•', ' ', 'It', 'is', 'scalable', '\\n\\n', '•', ' ', 'It', 'allows', 'categorization', 'and', 'linking', 'of', 'information', '\\n\\n', '•', ' ', 'It', 'can', 'be', 'applied', 'to', 'any', 'type', 'of', 'situation', ':', 'notetaking', ',', 'problem', 'solving', ',', 'analysis', ',', 'creation', 'of', ' ', 'new', 'ideas', '\\n\\n', '•', ' ', 'It', 'is', 'suitable', 'for', 'all', 'people', 'and', 'is', 'easy', 'to', 'learn', '\\n\\n', '•', ' ', 'It', 'is', 'fun', 'and', 'encourages', 'exchanges', '\\n\\n', '•', ' ', 'It', 'makes', 'visible', 'the', 'dimension', 'of', 'projects', ',', 'opportunities', ',', 'interconnections', '\\n\\n', '•', ' ', 'It', 'synthesizes', '\\n\\n', '•', ' ', 'It', 'makes', 'the', 'project', 'understandable', '\\n\\n', '•', ' ', 'It', 'allows', 'you', 'to', 'explore', 'ideas', '\\n\\n', 'The', 'creation', 'of', 'a', 'mind', 'map', 'starts', 'with', 'an', 'idea', '/', 'problem', 'located', 'at', 'its', 'center', '.', 'This', 'starting', 'point', ' ', 'generates', 'ideas', '/', 'work', 'areas', ',', 'incremented', 'around', 'this', 'center', 'in', 'a', 'radial', 'structure', ',', 'which', 'in', 'turn', 'is', ' ', 'completed', 'with', 'as', 'many', 'branches', 'as', 'new', 'ideas', '.', '\\n\\n', 'This', 'tool', 'enables', 'creativity', 'and', 'logic', 'to', 'be', 'mobilized', ',', 'it', 'is', 'a', 'map', 'of', 'the', 'thoughts', '.', '\\n\\n', 'Creativity', 'is', 'enhanced', 'because', 'participants', 'feel', 'comfortable', 'with', 'the', 'method', '.', '\\n\\n', 'Application', '&', 'Insight', '\\n\\n', 'I', 'start', 'the', 'process', 'of', 'the', 'mind', 'map', 'creation', 'with', 'the', 'stakeholders', 'standing', 'around', 'a', 'large', 'board', ' ', '(', 'white', 'or', 'paper', 'board', ')', '.', 'In', 'the', 'center', 'of', 'the', 'board', ',', 'I', 'write', 'and', 'highlight', 'the', 'topic', 'to', 'design', '.', '\\n\\n', 'Through', 'a', 'series', 'of', 'questions', ',', 'I', 'guide', 'the', 'stakeholders', 'in', 'modelling', 'the', 'mind', 'map', '.', 'I', 'adapt', 'the', 'series', ' ', 'of', 'questions', 'according', 'to', 'the', 'topic', 'to', 'be', 'addressed', '.', 'In', 'the', 'type', 'of', 'questions', ',', 'we', 'can', 'use', ':', 'who', ',', 'what', ',', ' ', 'when', ',', 'where', ',', 'why', ',', 'how', ',', 'how', 'much', '.', '\\n\\n', 'The', 'use', 'of', 'the', '“', 'why', '”', 'is', 'very', 'interesting', 'to', 'understand', 'the', 'origin', '.', 'By', 'this', 'way', ',', 'the', 'interviewed', 'person', ' ', 'frees', 'itself', 'from', 'paradigms', 'and', 'thus', 'dares', 'to', 'propose', 'new', 'ideas', '/', 'ways', 'of', 'functioning', '.', 'I', 'plan', 'two', ' ', 'hours', 'for', 'a', 'workshop', '.', '\\n\\n', 'Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'After', 'modelling', 'the', 'mind', 'map', 'on', 'paper', ',', 'I', 'propose', 'to', 'the', 'participants', 'a', 'digital', 'visualization', 'of', 'their', ' ', 'work', 'with', 'the', 'addition', 'of', 'color', 'codes', ',', 'images', 'and', 'interconnections', '.', 'This', 'second', 'workshop', 'also', 'lasts', ' ', 'two', 'hours', 'and', 'allows', 'the', 'mind', 'map', 'to', 'evolve', '.', 'Once', 'familiarized', 'with', 'it', ',', 'the', 'stakeholders', 'discover', ' ', 'the', 'power', 'of', 'the', 'tool', '.', 'Then', ',', 'the', 'second', 'workshop', 'brings', 'out', 'even', 'more', 'ideas', 'and', 'constructive', ' ', 'exchanges', 'between', 'the', 'stakeholders', '.', 'Around', 'this', 'new', 'mind', 'map', ',', 'they', 'have', 'learned', 'to', 'work', ' ', 'together', 'and', 'want', 'to', 'make', 'visible', 'the', 'untold', 'ideas', '.', '\\n\\n', 'I', 'now', 'present', 'all', 'the', 'projects', 'I', 'manage', 'in', 'this', 'type', 'of', 'format', 'in', 'order', 'to', 'ease', 'rapid', 'understanding', 'for', ' ', 'decision', '-', 'makers', '.', 'These', 'presentations', 'are', 'the', 'core', 'of', 'my', 'business', 'models', '.', 'The', 'decision', '-', 'makers', 'are', ' ', 'thus', 'able', 'to', 'identify', 'the', 'opportunities', 'of', 'the', 'projects', 'and', 'can', 'take', 'quick', 'decisions', 'to', 'validate', 'them', '.', ' ', 'They', 'find', 'answers', 'to', 'their', 'questions', 'thank', 'to', 'a', 'schematic', 'representation', '.', '\\n\\n', 'Approach', '\\n\\n', 'What', 'I', 'find', 'amazing', 'with', 'the', 'facilitation', 'of', 'this', 'type', 'of', 'workshop', 'is', 'the', 'participants', 'commitment', 'for', ' ', 'the', 'project', '.', 'This', 'tool', 'helps', 'to', 'give', 'meaning', '.', 'The', 'participants', 'appropriate', 'the', 'story', 'and', 'want', 'to', 'keep', ' ', 'writing', 'it', '.', 'Then', ',', 'they', 'easily', 'become', 'actors', 'or', 'sponsors', 'of', 'the', 'project', '.', 'A', 'trust', 'relationship', 'is', 'built', ',', ' ', 'thus', 'facilitating', 'the', 'implementation', 'of', 'related', 'actions', '.', '\\n\\n', 'Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'Annex', '1', ':', 'Mind', 'Map', 'Shared', 'facilities', 'project', '\\n\\n']\n",
      "\n",
      "### Sample Trailing Whitespace ###\n",
      "The trailing_whitespce of this sample is: [True, True, True, True, False, False, True, False, False, True, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, False, False, True, False, False, True, False, True, True, True, False, False, False, True, True, True, True, False, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, False, True, True, False, False, True, True, True, True, False, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, False, True, True, False, False, True, False, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, True, False, True, False, True, True, False, True, False, True, True, True, False, True, False, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, False, True, False, True, False, False, True, False, True, False, False, True, False, True, True, True, True, False, False, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, False, True, True, True, True, False, True, False, False, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, False, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, False, True, False, True, False, True, False, False, True, False, True, False, True, False, True, True, False, False, False, True, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, False, False, False, True, True, True, True, False, False, True, False, False, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, False, True, True, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, False, True, True, True, True, True, True, False, False, False, True, True, True, True, False, False, True, False, False, True, False, False, True, False, True, True, True, True, True, False, False]\n",
      "### Sample Labels ###\n",
      "The labels of this sample is: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "#### gain insight from an example \n",
    "# data is a list contains multiple dictionaries, choose the first dictionary\n",
    "# as an example\n",
    "example = data[0]\n",
    "print(\"### Data Size ###\")\n",
    "print(f\"The length of the data is: {len(data)}\\n\")\n",
    "\n",
    "print(\"### Sample Keys ###\")\n",
    "print(f'The keys of the data is: {example.keys()}\\n')\n",
    "\n",
    "print(\"### Sample Document Number ###\")\n",
    "print(f\"The document of this sample is: {example['document']}\\n\")\n",
    "\n",
    "print(\"### Sample Full Text ###\")\n",
    "print(f\"The full_text of this sample is: {example['full_text']}\\n\")\n",
    "\n",
    "print(\"### Sample Tokens ###\")\n",
    "print(f\"The tokens of this sample is: {example['tokens']}\\n\")\n",
    "\n",
    "print(\"### Sample Trailing Whitespace ###\")\n",
    "print(f\"The trailing_whitespce of this sample is: {example['trailing_whitespace']}\")\n",
    "\n",
    "print(\"### Sample Labels ###\")\n",
    "print(f\"The labels of this sample is: {example['labels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc80056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T06:34:31.825727Z",
     "iopub.status.busy": "2024-02-02T06:34:31.825375Z",
     "iopub.status.idle": "2024-02-02T06:34:31.840361Z",
     "shell.execute_reply": "2024-02-02T06:34:31.839406Z"
    },
    "papermill": {
     "duration": 0.022166,
     "end_time": "2024-02-02T06:34:31.842544",
     "exception": false,
     "start_time": "2024-02-02T06:34:31.820378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### downsize the data size\n",
    "positive_samples = [] # samples that contain named entities\n",
    "negative_samples = [] # samples that do not contain any named entity\n",
    "\n",
    "for sentence in data:\n",
    "    # check if the sentence contains any named entities\n",
    "    if any(label != '0' for label in sentence['labels']):\n",
    "        positive_samples.append(sentence)\n",
    "    else:\n",
    "        negative_samples.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc1a1e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T06:34:31.852374Z",
     "iopub.status.busy": "2024-02-02T06:34:31.851111Z",
     "iopub.status.idle": "2024-02-02T06:34:32.012082Z",
     "shell.execute_reply": "2024-02-02T06:34:32.010772Z"
    },
    "papermill": {
     "duration": 0.168185,
     "end_time": "2024-02-02T06:34:32.014496",
     "exception": false,
     "start_time": "2024-02-02T06:34:31.846311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## All Labels ########\n",
      "['B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', 'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', 'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL', 'O']\n",
      "######## Labels to ID ########\n",
      "{'B-EMAIL': 0, 'B-ID_NUM': 1, 'B-NAME_STUDENT': 2, 'B-PHONE_NUM': 3, 'B-STREET_ADDRESS': 4, 'B-URL_PERSONAL': 5, 'B-USERNAME': 6, 'I-ID_NUM': 7, 'I-NAME_STUDENT': 8, 'I-PHONE_NUM': 9, 'I-STREET_ADDRESS': 10, 'I-URL_PERSONAL': 11, 'O': 12}\n",
      "######## ID to Labels ########\n",
      "{0: 'B-EMAIL', 1: 'B-ID_NUM', 2: 'B-NAME_STUDENT', 3: 'B-PHONE_NUM', 4: 'B-STREET_ADDRESS', 5: 'B-URL_PERSONAL', 6: 'B-USERNAME', 7: 'I-ID_NUM', 8: 'I-NAME_STUDENT', 9: 'I-PHONE_NUM', 10: 'I-STREET_ADDRESS', 11: 'I-URL_PERSONAL', 12: 'O'}\n"
     ]
    }
   ],
   "source": [
    "#### creating label-id mappings for data labels\n",
    "# flatten all labels from the 'labels' key in each item of 'data' and remove duplicates\n",
    "all_labels = sorted({label for sentence in data for label in sentence['labels']})\n",
    "print('######## All Labels ########')\n",
    "print(all_labels)\n",
    "\n",
    "# create a dictionary mapping each label to a unique ID using enumerate\n",
    "label2id = {label: id for id, label in enumerate(all_labels)}\n",
    "print('######## Labels to ID ########')\n",
    "print(label2id)\n",
    "\n",
    "# reverse the label2id dict to create a mapping from IDs back to labels\n",
    "id2label = {id: label for label, id in label2id.items()}\n",
    "print('######## ID to Labels ########')\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0fcf63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T06:34:32.023679Z",
     "iopub.status.busy": "2024-02-02T06:34:32.023334Z",
     "iopub.status.idle": "2024-02-02T06:34:32.032635Z",
     "shell.execute_reply": "2024-02-02T06:34:32.031403Z"
    },
    "papermill": {
     "duration": 0.016564,
     "end_time": "2024-02-02T06:34:32.034986",
     "exception": false,
     "start_time": "2024-02-02T06:34:32.018422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, label2id, max_length):\n",
    "    '''tokenize example'''\n",
    "    \n",
    "    # rebuild text from tokens and labels, adding spaces\n",
    "    rebuilt_text = \"\".join(token + \" \" * ws for token, ws in zip(example['tokens'], example['trailing_whitespace']))\n",
    "    labels = [l for label in example['provided_labels'] for l in label * len(token)] + ['0'] * example['trailing_whitespace'].count(True)\n",
    "    \n",
    "    # tokenize the text\n",
    "    tokenized_input = tokenizer(rebuilt_text, return_offsets_mapping=True, max_length=max_length, truncation=True)\n",
    "    # create labels for subtokens\n",
    "    subtoken_labels = []\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    for start_idx, end_idx in tokenized_input.offset_mapping:\n",
    "        # check if the offset mapping corresponds to a special token\n",
    "        if start_idx == end_idx == 0:\n",
    "            # append the label ID for a special token ('0')\n",
    "            subtoken_labels.append(label2id['0'])\n",
    "        else:\n",
    "            # if the character at start_idx is a whitespace, move to the next character\n",
    "            start_idx += rebuilt_text[start_idx].isspace()\n",
    "            # append the label ID for the subtoken, using the adjusted start_idx\n",
    "            subtoken_labels.append(label2id[labels[start_idx]])\n",
    "    \n",
    "    # remove offset mapping before returning as it's not needed anymore\n",
    "    tokenized_input.pop('offset_mapping')\n",
    "    \n",
    "    # python dictionary comprehension\n",
    "    return {\n",
    "        **tokenized_input, # unpacks the original tokenized_input dictionary into the new dictionary\n",
    "        'labels': subtoken_labels, # adds a new key 'labels' with its value being whatever subtoken_labels is\n",
    "        'length': len(tokenized_input['input_ids']) # adds another key value pair\n",
    "    }\n",
    "                                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778d22fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T06:34:32.043971Z",
     "iopub.status.busy": "2024-02-02T06:34:32.043621Z",
     "iopub.status.idle": "2024-02-02T06:34:32.048664Z",
     "shell.execute_reply": "2024-02-02T06:34:32.047419Z"
    },
    "papermill": {
     "duration": 0.012081,
     "end_time": "2024-02-02T06:34:32.050916",
     "exception": false,
     "start_time": "2024-02-02T06:34:32.038835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # a tokenizer compatible with the model to be trained is loaded from a given path\n",
    "# tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n",
    "\n",
    "# # prepare the dataset \n",
    "# processed_dataset = Dataset.from_dict({\n",
    "#     'full_text': [x['full_text'] for x in data],\n",
    "#     'document': [str(x['document']) for x in data],\n",
    "#     'tokens': [x['tokens'] for x in data],\n",
    "#     'trailing_whitespace': [x['trailing_whitespace'] for x in data],\n",
    "#     # rename 'labels' to 'provided_labels'\n",
    "#     'provided_labels': [x['labels'] for x in data] \n",
    "# })\n",
    "\n",
    "# # appply the tokenize function\n",
    "# # the map() will apply tokenize() to every value of the dataset\n",
    "# processed_dataset = processed_dataset.map(\n",
    "#     tokenize, # the tokenize() is applied in the dataset\n",
    "#     fn_kwargs={\n",
    "#         \"tokenizer\": tokenizer, \n",
    "#         \"label2id\": label2id, \n",
    "#         \"max_length\": TRAINING_MAX_LENGTH\n",
    "#     }, \n",
    "#     num_proc=3 # 3 parallel processes \n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31.069307,
   "end_time": "2024-02-02T06:34:34.681963",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-02T06:34:03.612656",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
